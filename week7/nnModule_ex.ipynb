{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ds6G9QrsoajU",
        "lVelds5Po2mj",
        "R5q6WGT9pJAT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbHACDwZahrN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# top-level atrri.로 sub-module 추가"
      ],
      "metadata": {
        "id": "pIjf9zjli3Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Module, init, Linear, Parameter, ReLU\n",
        "from torch import optim\n",
        "\n",
        "class DsANN (Module): #custom module\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_in_f,  # input vector의 차원수.\n",
        "                 n_out_f, # output vector의 차원수.\n",
        "                 ):\n",
        "        super().__init__() # required!\n",
        "\n",
        "        self.linear0 = Linear(n_in_f, 32)\n",
        "        self.relu0 = ReLU()\n",
        "\n",
        "        self.linear1 = Linear(32, 32)\n",
        "        self.relu1 = ReLU()\n",
        "\n",
        "        self.linear2 = Linear(32, n_out_f)\n",
        "\n",
        "        with torch.no_grad():\n",
        "        #  이 블록 내에서의 연산은 자동 미분(autograd)에서 제외\n",
        "            # linear0의 bias를 상수 0. 으로 초기화\n",
        "            init.constant_(self.linear0.bias, 0.)\n",
        "\n",
        "            # Xavier 초기화 방식으로 초기화\n",
        "            init.xavier_uniform_(self.linear0.weight)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.linear0(x)\n",
        "        x = self.relu0(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu1(x)\n",
        "        y = self.linear2(x)\n",
        "        return y"
      ],
      "metadata": {
        "id": "QA_MlDxOi3EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# add_module로 sub-module 추가"
      ],
      "metadata": {
        "id": "oPPyiusmj1xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DsANN (Module): #custom module\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_in_f,  # input vector의 차원수.\n",
        "                 n_out_f, # output vector의 차원수.\n",
        "                 ):\n",
        "        super().__init__() # required!\n",
        "\n",
        "        self.add_module('linear0', Linear(n_in_f, 32))\n",
        "        self.add_module('relu0', ReLU())\n",
        "        self.add_module('linear1', Linear(32, 32))\n",
        "        self.add_module('relu1', ReLU())\n",
        "        self.add_module('linear2', Linear(32, n_out_f))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Module의 apply는 특정 함수를 자신의 submodules에 모두 적용 (재귀적).\n",
        "            self.apply(self.init_weight)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        for c in self.children():\n",
        "            x=c(x)\n",
        "        return x\n",
        "\n",
        "        # x = self.linear0(x)\n",
        "        # x = self.relu0(x)\n",
        "        # x = self.linear1(x)\n",
        "        # x = self.relu1(x)\n",
        "        # x = self.linear2(x)\n",
        "        # return x\n",
        "\n",
        "    @classmethod\n",
        "    def init_weight(cls, module):\n",
        "        if type(module) == torch.nn.Linear:\n",
        "            init.kaiming_uniform_(module.weight, mode='fan_in', nonlinearity='relu')\n",
        "            # init.ones_(module.weight)\n",
        "            init.constant_(module.bias, 0)\n",
        "\n",
        "model = DsANN(1,1)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vldlVGTTj7LS",
        "outputId": "0a621bd9-2696-4c28-c3f0-9b1f2fd378ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DsANN(\n",
            "  (linear0): Linear(in_features=1, out_features=32, bias=True)\n",
            "  (relu0): ReLU()\n",
            "  (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.ModuleList, nn.ModuleDict, nn.Sequential 사용법/유의사항"
      ],
      "metadata": {
        "id": "FRUkp0iloW1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Sequential"
      ],
      "metadata": {
        "id": "ds6G9QrsoajU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10),\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBTtt5TukYex",
        "outputId": "e642f204-51e3-4b42-b9e0-aeee58af41b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=20, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Sequential은 nn.Linear와 nn.ReLU 모듈을 순차적으로 포함하고 있으며, 정의한 순서대로 순차적으로 적용"
      ],
      "metadata": {
        "id": "dj_emCbvo1Zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.ModuleList"
      ],
      "metadata": {
        "id": "lVelds5Po2mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Linear(10, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 10)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Y9d0BAotuv",
        "outputId": "3b269fbc-62c6-4f2e-e2d6-fa701d07d789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=20, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적인 Python 리스트와 유사하게 동작하지만,\n",
        "\n",
        "리스트에 포함된 모든 모듈이 PyTorch의 모델 구성 요소로 인식되어 올바르게 등록되고 관리됨.\n",
        "\n",
        "이는 모델 파라미터가 자동으로 추적되며, to(), cuda(), cpu()와 같은 메서드를 사용할 수 있게 함"
      ],
      "metadata": {
        "id": "E0T7DN-apLub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.ModuleDict"
      ],
      "metadata": {
        "id": "R5q6WGT9pJAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layers = nn.ModuleDict({\n",
        "            'fc1': nn.Linear(10, 20),\n",
        "            'relu': nn.ReLU(),\n",
        "            'fc2': nn.Linear(20, 10)\n",
        "        })\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers['fc1'](x)\n",
        "        x = self.layers['relu'](x)\n",
        "        x = self.layers['fc2'](x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-n9Vx9QpRuG",
        "outputId": "34ca7392-e664-42ab-cf11-f5e42c364119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (layers): ModuleDict(\n",
            "    (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
            "    (relu): ReLU()\n",
            "    (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적인 Python 딕셔너리와 유사하게 동작하지만,\n",
        "\n",
        "딕셔너리에 포함된 모든 모듈이 PyTorch의 모델 구성 요소로 인식되어 올바르게 등록되고 관리됨.\n",
        "\n",
        "이는 모델 파라미터가 자동으로 추적되며, to(), cuda(), cpu()와 같은 메서드를 사용할 수 있게 함."
      ],
      "metadata": {
        "id": "Tlld5U0ypWE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 일반 list나 dict로 할 경우, 발생하는 문제"
      ],
      "metadata": {
        "id": "uZMNAGGwpX17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "self.layers에 일반 list를 사용하면, 모델의 파라미터가 자동으로 추적되지 않음."
      ],
      "metadata": {
        "id": "CqarlJmKphcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layers = [\n",
        "            nn.Linear(10, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 10)\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "print(model)\n",
        "print(\"Model parameters:\", list(model.parameters()))  # 파라미터가 추적되지 않음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImLM8Ru-pWXd",
        "outputId": "ea49ecd9-82a7-4b08-a1e9-1a67480cba59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel()\n",
            "Model parameters: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layers = [\n",
        "            nn.Linear(10, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 10)\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "model_gpu = model.to('cuda')  # 일반 list를 사용하면 GPU로 이동하지 않음"
      ],
      "metadata": {
        "id": "Z8qypO4SqFOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDmgNxjbqRNb",
        "outputId": "d6f54898-bdc4-4446-dbe8-bcb25bc8a500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel()"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1AVz6pKqT9u",
        "outputId": "bc3a6677-c3fa-47de-cff6-2219d9791769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel()"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module의 methods\n",
        "* .parameters(recures=True)\n",
        "* .name_buffers()\n",
        "* .children()\n",
        "* .modules()"
      ],
      "metadata": {
        "id": "dWtVOVFZqYfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleLinear(Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super().__init__()\n",
        "\n",
        "        tmp = [(n_in, n_out), (n_out, n_out)]\n",
        "        for idx, t in enumerate(tmp):\n",
        "            self.add_module(f'linear{idx}', Linear(*t)) # *t는 unpacking 문법. list, tuple 같은 iterable 객체의 요소들을 개별적으로 풀어서 함수,메소드에 전달.\n",
        "            self.add_module(f'relu{idx}', ReLU())\n",
        "\n",
        "    def forward(self,x):\n",
        "        for c in self.children():\n",
        "            x=c(x)\n",
        "        return x\n",
        "\n",
        "class DsANN (Module): #custom module\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_in_f,  # input vector의 차원수.\n",
        "                 n_out_f, # output vector의 차원수.\n",
        "                 ):\n",
        "        super().__init__() # required!\n",
        "\n",
        "        self.add_module('module1', DoubleLinear(n_in_f,32))\n",
        "        self.add_module('module2', Linear(32, n_out_f))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.apply(self.init_weight)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        for c in self.children():\n",
        "            x=c(x)\n",
        "        return x\n",
        "\n",
        "    @classmethod\n",
        "    def init_weight(cls, module):\n",
        "        if type(module) == torch.nn.Linear:\n",
        "            init.kaiming_uniform_(module.weight, mode='fan_in', nonlinearity='relu')\n",
        "            # init.ones_(module.weight)\n",
        "            init.constant_(module.bias, 0)\n",
        "\n",
        "model = DsANN(1,1)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6vdtts7rvMs",
        "outputId": "1df2b640-2d28-4463-d8e1-9cd03f6485a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DsANN(\n",
            "  (module1): DoubleLinear(\n",
            "    (linear0): Linear(in_features=1, out_features=32, bias=True)\n",
            "    (relu0): ReLU()\n",
            "    (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (relu1): ReLU()\n",
            "  )\n",
            "  (module2): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  `__call__` 와 forward"
      ],
      "metadata": {
        "id": "9FrFl_BztOs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"forward called\")\n",
        "        return self.linear(x)\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# 일반적인 방식 (추천 방식)\n",
        "x = torch.randn(1, 10)\n",
        "output = model(x)  # 내부적으로 model.__call__(x) → model.forward(x) 호출됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL6B4DzStS1w",
        "outputId": "7786a821-e585-4b60-cec3-1ac03f6145d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward called\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================="
      ],
      "metadata": {
        "id": "zTcMeRpnye6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hook"
      ],
      "metadata": {
        "id": "un4KyvRmyhPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "XQ8-8c9YvDUX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "816c61b5-b07d-41af-ecc4-60bbd7079792"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 모델 정의\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(4, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = SimpleModel()"
      ],
      "metadata": {
        "id": "ODsFwvywyo57"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. forward Pre-hook 등록\n",
        "def pre_hook(module, input):\n",
        "  print(f\"[Pre-Hook] input: {input}\")\n",
        "  return input\n",
        "\n",
        "model.linear.register_forward_pre_hook(pre_hook)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zARozraqy5m8",
        "outputId": "70295d28-2d74-452a-d5d0-586a90b0e08d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7efb96918d50>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. forward hook 등록\n",
        "def forward_hook(module, input, output):\n",
        "    print(f\"[Forward Hook] output: {output}\")\n",
        "\n",
        "model.linear.register_forward_hook(forward_hook)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-EXj3uBzbWg",
        "outputId": "28bb33f0-7e1e-4a03-e525-6fae27d1ca28"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7efb966b3fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. backward hook 등록 (module)\n",
        "def bakcward_hook_module(module, grad_input, grad_output):\n",
        "    print(f\"[Backward Hook] grad_input: {grad_input}, grad_output: {grad_output}\")\n",
        "\n",
        "model.linear.register_backward_hook(bakcward_hook_module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPFlLnGyzk9w",
        "outputId": "612799a6-292c-41df-9bb0-548cfdabefb7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7efb87747e10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. tensor gradient hook 등록\n",
        "#    역전파 중에 해당 tensor에 도달했을 때,\n",
        "#    해당 tensor의 gradient가 계산되기 위해\n",
        "#    backward propagation으로 입력된 grad임.\n",
        "def tensor_hook(grad):\n",
        "  print(f\"[Tensor Hook] grad: {grad}\")\n",
        "  return grad\n",
        "\n",
        "# 이후 tensor객체에 대해 직접 register_hook 메서드로 callback을 넘김."
      ],
      "metadata": {
        "id": "jhQ7q9qPz395"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 입력 생성 및 forward/backward 실행 / Tensor Gradient Hook 등록\n",
        "x = torch.tensor([[1.0, 2.0, 3.0, 4.0]], requires_grad=True)\n",
        "y = model(x)\n",
        "y.register_hook(tensor_hook)  # tensor에 직접 hook\n",
        "loss = y.sum()\n",
        "loss.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FMXgqmd0Jun",
        "outputId": "348843a9-d5a2-4993-ecae-594eb5c82fd2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pre-Hook] input: (tensor([[1., 2., 3., 4.]], requires_grad=True),)\n",
            "[Forward Hook] output: tensor([[0.7827, 2.1173]], grad_fn=<AddmmBackward0>)\n",
            "[Tensor Hook] grad: tensor([[1., 1.]])\n",
            "[Backward Hook] grad_input: (tensor([1., 1.]), tensor([[0.2771, 0.2291, 0.4423, 0.4151]]), tensor([[1., 1.],\n",
            "        [2., 2.],\n",
            "        [3., 3.],\n",
            "        [4., 4.]])), grad_output: (tensor([[1., 1.]]),)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tEaMX5i0om4",
        "outputId": "dbc8b921-a3ab-46f4-c5ef-3a70fccd9c3c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2771, 0.2291, 0.4423, 0.4151]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. forwaerd / backward 실행\n",
        "y = model(x)\n",
        "loss = y.sum()\n",
        "loss.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb_-KyEh0rlB",
        "outputId": "8ff68a1e-aaad-44d8-e61e-77f19422ae3d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pre-Hook] input: (tensor([[1., 2., 3., 4.]], requires_grad=True),)\n",
            "[Forward Hook] output: tensor([[0.7827, 2.1173]], grad_fn=<AddmmBackward0>)\n",
            "[Backward Hook] grad_input: (tensor([1., 1.]), tensor([[0.2771, 0.2291, 0.4423, 0.4151]]), tensor([[1., 1.],\n",
            "        [2., 2.],\n",
            "        [3., 3.],\n",
            "        [4., 4.]])), grad_output: (tensor([[1., 1.]]),)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1830: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 참고: Tensor의 register_hook 동작."
      ],
      "metadata": {
        "id": "K45BEls106Or"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`register_hook`은 **\"등록된 해당 텐서의 `grad_fn`으로 들어오는 역전파 grad\"**에 hook이 걸림.\n",
        "\n",
        "즉,\n",
        "\n",
        "`y.register_hook(hook)`은\n",
        "\n",
        "* **\"역전파 중에 `y`에 도달했을 때, `y`의 `grad`가 계산되기 직전에\n",
        "* 입력으로 들어오는 `grad`\"**를 hook 함수에 넘김.\n",
        "* 이때 넘겨지는 `grad`는 `y` 텐서의 뒤쪽 노드에서 넘겨받은 gradient임."
      ],
      "metadata": {
        "id": "_rD6af6c07kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.tensor(2.0, requires_grad=True)\n",
        "y1 = x1 ** 2\n",
        "z1 = y1 * 3\n",
        "\n",
        "def hook_fn(grad):\n",
        "    print(\"y1에 전달된 grad:\", grad)\n",
        "    return grad\n",
        "\n",
        "y1.register_hook(hook_fn)\n",
        "z1.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tdYUmsC00Q9",
        "outputId": "9db2605a-d97f-440d-9821-ad3603cd49d2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y1에 전달된 grad: tensor(3.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 계산 흐름은 다음과 같음:\n",
        "\n",
        "* `z1 = 3 * y1`, 그러므로 `dz1/dy1 = 3`\n",
        "* `y1 = x1 ** 2`, 그러므로 `dy1/dx1 = 2x1 = 4`\n",
        "\n",
        "전체적으로:\n",
        "\n",
        "`z.backward() → y`로 전달되는 `grad_output = 3`\n",
        "\n",
        "그걸 hook에서 \"받아서\" 출력함: `y`에 전달된 `grad: tensor(3.)`"
      ],
      "metadata": {
        "id": "aEhjoZE61dLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# +) hook 해제"
      ],
      "metadata": {
        "id": "1QFOfPt51eUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "linear = nn.Linear(2, 1)\n",
        "\n",
        "def backward_hook(mod, grad_in, grad_out):\n",
        "    print(\"Backward hook called\")\n",
        "\n",
        "# hook 등록\n",
        "handle = linear.register_full_backward_hook(backward_hook)\n",
        "\n",
        "# 학습 과정 중...\n",
        "x = torch.randn(1, 2, requires_grad=True)\n",
        "y = linear(x)\n",
        "y.sum().backward()  # hook 실행됨\n",
        "\n",
        "# hook 해제\n",
        "handle.remove()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ic7y8dZ1WAi",
        "outputId": "7d6b4855-4008-4123-8b03-dabe17d99f85"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backward hook called\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = linear(x)\n",
        "y.sum().backward() # hook 해제되어 hook 실행X"
      ],
      "metadata": {
        "id": "vKRaXdz22LHi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5PpUv5Wt2Vug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ======================================================="
      ],
      "metadata": {
        "id": "YJamTKru2Y1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and Load"
      ],
      "metadata": {
        "id": "9BFN34ju4ucS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# state_dict로 parameters만을 저장하고 로드"
      ],
      "metadata": {
        "id": "kdAcYo754w9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 library와 모듈 import\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from collections import OrderedDict\n",
        "\n",
        "# 간단한 linear regression model 정의.\n",
        "# SimpleModel0와 SimpleModel1은\n",
        "# 똑같은 구조이나 파라메터들의 초기값만 다름.\n",
        "class SimpleModel0(nn.Module):\n",
        "\n",
        "    def __init__(self, n_in_f, n_out_f):\n",
        "        super().__init__()\n",
        "\n",
        "        self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "        const_weight = 1.\n",
        "        const_bias = 0.5\n",
        "        init.constant_(self.l0.weight, const_weight)\n",
        "        if self.l0.bias is not None:\n",
        "            init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.l0(x)\n",
        "\n",
        "\n",
        "class SimpleModel1(nn.Module):\n",
        "\n",
        "    def __init__(self, n_in_f, n_out_f):\n",
        "        super().__init__()\n",
        "\n",
        "        self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "        const_weight = 2.\n",
        "        const_bias = 1.5\n",
        "\n",
        "        init.constant_(self.l0.weight, const_weight)\n",
        "        if self.l0.bias is not None:\n",
        "            init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.l0(x)\n",
        "\n",
        "\n",
        "# 모델 객체를 생성하고, 이에 대한 파라메터 확인 후\n",
        "# 파라메터만 저장.\n",
        "model = SimpleModel0(3, 1)  # SimpleModel0 객체 생성\n",
        "print(\"Initial model parameters:\")\n",
        "print(list(model.named_parameters()))\n",
        "torch.save(model.state_dict(), 'model_params.pth')\n",
        "\n",
        "# 새로운 모델 객체를 생성.\n",
        "# 해당 모델 객체는 구조는 같으나, 파라메터들의 초기값은 다름.\n",
        "n_model = SimpleModel1(3, 1)\n",
        "\n",
        "print('===============')\n",
        "# 이전 모델(SimpleModel0)과 새로운 모델(SimpleModel1)의 파라메터 비교\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "    if not torch.equal(old, new):\n",
        "        print('model and n_model w/ default init do not have parameters with the same values!')\n",
        "        break\n",
        "else:\n",
        "    print('model and n_model w/ default init have parameters with the same values!')\n",
        "print('===============') # break checker부분?\n",
        "\n",
        "# 이전 저장한 parameters에 대한 state_dict를\n",
        "# 로드하고 해당 state_dict로 새로 만든 모델의\n",
        "# 파라메터를 설정하고 이전 모델과 비교.\n",
        "# load parameters and restore old parameters into new model\n",
        "loaded_params_ordered_dict = torch.load('model_params.pth')\n",
        "print(f'{type(loaded_params_ordered_dict)=}')  # collections.OrderedDict\n",
        "\n",
        "ret_v = n_model.load_state_dict(loaded_params_ordered_dict)\n",
        "print(f'{type(ret_v)}: {ret_v}')\n",
        "\n",
        "print('===============')\n",
        "# 이전 모델(SimpleModel0)과 새로 로드된 파라메터로 설정된 모델(SimpleModel1)의 파라메터 비교\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "    if not torch.equal(old, new):\n",
        "        print('model and n_model do not have parameters with the same values!')\n",
        "        break\n",
        "else:\n",
        "    print('model and n_model have parameters with the same values!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aPgbstJ2aFg",
        "outputId": "48126078-fd37-4e63-8101-f67952631326"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial model parameters:\n",
            "[('l0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1.]], requires_grad=True)), ('l0.bias', Parameter containing:\n",
            "tensor([0.5000], requires_grad=True))]\n",
            "===============\n",
            "model and n_model w/ default init do not have parameters with the same values!\n",
            "===============\n",
            "type(loaded_params_ordered_dict)=<class 'collections.OrderedDict'>\n",
            "<class 'torch.nn.modules.module._IncompatibleKeys'>: <All keys matched successfully>\n",
            "===============\n",
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------------------------------------------"
      ],
      "metadata": {
        "id": "dmL7SLvE5wRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "Yj780IXv43nK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel0(nn.Module):\n",
        "\n",
        "  def __init__(self, n_in_f, n_out_f):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "    const_weight = 1.\n",
        "    const_bias = 0.5\n",
        "\n",
        "    init.constant_(self.l0.weight, const_weight)\n",
        "    if self.l0.bias is not None:\n",
        "      init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l0(x)"
      ],
      "metadata": {
        "id": "4Ec-03736B1U"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel1(nn.Module):\n",
        "\n",
        "  def __init__(self, n_in_f, n_out_f):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "    self.l1 = nn.Linear(n_out_f, n_out_f)\n",
        "\n",
        "    const_weight = 2.\n",
        "    const_bias = 1.5\n",
        "\n",
        "    init.constant_(self.l0.weight, const_weight)\n",
        "    if self.l0.bias is not None:\n",
        "      init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l0(x)"
      ],
      "metadata": {
        "id": "cpKWv8yr6G4e"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel0(3, 1)\n",
        "\n",
        "print(list(model.named_parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzuw9rDy6INR",
        "outputId": "86f7939b-3aee-4593-9f68-773ddcea826f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('l0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1.]], requires_grad=True)), ('l0.bias', Parameter containing:\n",
            "tensor([0.5000], requires_grad=True))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ordered_dict_params = model.state_dict()\n",
        "for c in ordered_dict_params.items():\n",
        "  print(f'{c[0]:<10}={c[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Y0w01T6PKL",
        "outputId": "b3fb90e7-0420-4a74-8b8b-5dd9c02a63ce"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l0.weight =tensor([[1., 1., 1.]])\n",
            "l0.bias   =tensor([0.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_params.pth')"
      ],
      "metadata": {
        "id": "MXcBFHDS6TS0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_model = SimpleModel1(3, 1)\n",
        "\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "  if not torch.equal(old, new):\n",
        "    print('model and n_model do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBZdiovL6cTd",
        "outputId": "9db97fe2-afaf-42ee-ace7-ca262e742559"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model and n_model do not have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load parameters and restore old parameters into new model\n",
        "loaded_params_ordered_dict = torch.load('model_params.pth')\n",
        "\n",
        "incompatible_keys = n_model.load_state_dict(loaded_params_ordered_dict)\n",
        "print(f'{type(incompatible_keys)}: {incompatible_keys}')\n",
        "print(f'{incompatible_keys.missing_keys=}')\n",
        "print(f'{incompatible_keys.unexpected_keys=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "nMH82WfF6mR3",
        "outputId": "9763ffd9-21d9-42c7-bd2f-dba13bfa5098"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for SimpleModel1:\n\tMissing key(s) in state_dict: \"l1.weight\", \"l1.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b207d86bc175>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloaded_params_ordered_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_params.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mincompatible_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_params_ordered_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(incompatible_keys)}: {incompatible_keys}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{incompatible_keys.missing_keys=}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SimpleModel1:\n\tMissing key(s) in state_dict: \"l1.weight\", \"l1.bias\". "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 수정해주신다고 해주심 (주말에 확인해서 적어두자)"
      ],
      "metadata": {
        "id": "whAGj8jq6sgj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A9X2dZ1G6psU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ====================================================="
      ],
      "metadata": {
        "id": "ASr1B54I6yBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model 전체를 저장하고 로드 (state_dict() 방식)"
      ],
      "metadata": {
        "id": "_y578CdP77HL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 모듈 import\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "\n",
        "# 사용할 간단한 linear regression model 정의\n",
        "class SimpleModel0(nn.Module):\n",
        "\n",
        "    def __init__(self, n_in_f, n_out_f):\n",
        "        super().__init__()\n",
        "\n",
        "        self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "        # 고정된 상수로 초기화\n",
        "        const_weight = 2.  # 가중치 초기화 값\n",
        "        const_bias = 1.5  # 편향 초기화 값\n",
        "\n",
        "        # 초기화 적용\n",
        "        init.constant_(self.l0.weight, const_weight)\n",
        "        if self.l0.bias is not None:\n",
        "            init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.l0(x)\n",
        "\n",
        "# 저장할 모델 생성.\n",
        "model = SimpleModel0(3, 1)\n",
        "\n",
        "# 모델의 state_dict만 저장\n",
        "torch.save(model.state_dict(), 'model_state_dict.pth')\n",
        "\n",
        "# 모델 로드 (모델 구조를 미리 정의한 후 state_dict를 로드)\n",
        "n_model = SimpleModel0(3, 1)  # 모델 구조를 새로 정의한 후\n",
        "n_model.load_state_dict(torch.load('model_state_dict.pth'))  # 파라미터만 로드\n",
        "\n",
        "print(f'{type(n_model)=}, {n_model}')\n",
        "\n",
        "# 두 모델의 parameters 비교.\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "    if not torch.equal(old, new):\n",
        "        print('model and n_model do not have parameters with the same values!')\n",
        "        break\n",
        "else:\n",
        "    print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb4M0RWU6z1W",
        "outputId": "79b6d179-d991-46f7-ccf9-d98649d4f220"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(n_model)=<class '__main__.SimpleModel0'>, SimpleModel0(\n",
            "  (l0): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래는 weights_inly=False 옵션 사용"
      ],
      "metadata": {
        "id": "0F2L4lEv8koL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 모듈 import\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from collections import OrderedDict\n",
        "\n",
        "# 사용할 간단한 linear regression model 정의\n",
        "class SimpleModel0(nn.Module):\n",
        "\n",
        "    def __init__(self, n_in_f, n_out_f):\n",
        "        super().__init__()\n",
        "\n",
        "        self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "        # 고정된 상수로 초기화\n",
        "        const_weight = 2.  # 가중치 초기화 값\n",
        "        const_bias = 1.5  # 편향 초기화 값\n",
        "\n",
        "        # 초기화 적용\n",
        "        init.constant_(self.l0.weight, const_weight)\n",
        "        if self.l0.bias is not None:\n",
        "            init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.l0(x)\n",
        "\n",
        "# 저장할 모델 생성.\n",
        "model = SimpleModel0(3, 1)\n",
        "\n",
        "# 모델 저장 (모델 객체 전체를 저장)\n",
        "torch.save(model, 'model.pth')\n",
        "\n",
        "# 저장된 model 로드 (weights_only=False로 설정)\n",
        "n_model = torch.load('model.pth', weights_only=False)\n",
        "\n",
        "# 로드된 모델 타입 확인\n",
        "print(f'{type(n_model)=}, {n_model}')\n",
        "\n",
        "# 두 모델의 parameters 비교.\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "    if not torch.equal(old, new):\n",
        "        print('model and n_model do not have parameters with the same values!')\n",
        "        break\n",
        "else:\n",
        "    print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hycoW2_s8B4d",
        "outputId": "0e6cd4ed-9d81-40ab-fb7d-3999f556d23c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(n_model)=<class '__main__.SimpleModel0'>, SimpleModel0(\n",
            "  (l0): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n",
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=========================================================="
      ],
      "metadata": {
        "id": "iEY9ajfV9vHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# state-dict 반환하는 예제 코드"
      ],
      "metadata": {
        "id": "1ekQpJ1-91kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "# 간단한 신경망 모델 클래스 정의\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        # 10차원 입력을 5차원으로 변환하는 선형 레이어 정의\n",
        "        self.linear = nn.Linear(10, 5)\n",
        "        # 5차원 특성에 대한 배치 정규화 레이어 정의\n",
        "        self.bn = nn.BatchNorm1d(5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 선형 변환 적용\n",
        "        x = self.linear(x)\n",
        "        # 배치 정규화 적용\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "# 모델 인스턴스 생성\n",
        "model = MyModel()\n",
        "\n",
        "# 모델의 state_dict 획득\n",
        "state_dict = model.state_dict()\n",
        "\n",
        "# 파라미터와 버퍼 구분을 위한 출력 섹션\n",
        "\n",
        "print(\"=== 파라미터 (학습 가능한 가중치) ===\")\n",
        "# named_parameters() 메서드를 통한 모든 파라미터 출력\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.shape}, requires_grad={param.requires_grad}\")\n",
        "\n",
        "print(\"\\n=== 버퍼 (학습 불가능한 상태 값) ===\")\n",
        "# named_buffers() 메서드를 통한 모든 버퍼 출력\n",
        "for name, buf in model.named_buffers():\n",
        "    print(f\"{name}: {buf.shape}, requires_grad={buf.requires_grad}\")\n",
        "\n",
        "print(\"\\n=== 전체 state_dict 내용 ===\")\n",
        "# 파라미터와 버퍼 키 목록 생성\n",
        "param_keys = [name for name, _ in model.named_parameters()]\n",
        "buffer_keys = [name for name, _ in model.named_buffers()]\n",
        "\n",
        "# state_dict의 각 항목에 대한 유형 구분\n",
        "for key, value in state_dict.items():\n",
        "    if key in param_keys:\n",
        "        print(f\"{key}: {value.shape} (파라미터)\")\n",
        "    elif key in buffer_keys:\n",
        "        print(f\"{key}: {value.shape} (버퍼)\")\n",
        "    else:\n",
        "        print(f\"{key}: {value.shape} (기타)\")\n",
        "\n",
        "# 예시 출력 설명:\n",
        "# - linear.weight, linear.bias: 선형 레이어의 학습 가능한 파라미터\n",
        "# - bn.weight, bn.bias: 배치 정규화의 학습 가능한 파라미터\n",
        "# - bn.running_mean, bn.running_var: 배치 정규화의 통계적 버퍼 값\n",
        "# - bn.num_batches_tracked: 배치 정규화의 추적용 버퍼 값"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCwLv8kA9z3i",
        "outputId": "a25f8abd-fba6-4baa-9536-a89346973a5f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 파라미터 (학습 가능한 가중치) ===\n",
            "linear.weight: torch.Size([5, 10]), requires_grad=True\n",
            "linear.bias: torch.Size([5]), requires_grad=True\n",
            "bn.weight: torch.Size([5]), requires_grad=True\n",
            "bn.bias: torch.Size([5]), requires_grad=True\n",
            "\n",
            "=== 버퍼 (학습 불가능한 상태 값) ===\n",
            "bn.running_mean: torch.Size([5]), requires_grad=False\n",
            "bn.running_var: torch.Size([5]), requires_grad=False\n",
            "bn.num_batches_tracked: torch.Size([]), requires_grad=False\n",
            "\n",
            "=== 전체 state_dict 내용 ===\n",
            "linear.weight: torch.Size([5, 10]) (파라미터)\n",
            "linear.bias: torch.Size([5]) (파라미터)\n",
            "bn.weight: torch.Size([5]) (파라미터)\n",
            "bn.bias: torch.Size([5]) (파라미터)\n",
            "bn.running_mean: torch.Size([5]) (버퍼)\n",
            "bn.running_var: torch.Size([5]) (버퍼)\n",
            "bn.num_batches_tracked: torch.Size([]) (버퍼)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Us0855A692t_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}